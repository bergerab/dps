* Data Processing System (DPS)
Data Processing System (DPS) is a platform for data analytics and visualization. The platform handles ingestion of data, specifying user-defined analytics on that data, and visualizing the results. The code is design in a micro-service oriented way. As an overview, the following is a comprehnsive list of micro-serivces and their purposes:

- ~DPS UI~: The user interface for both administrators and end-users (a React app).
- ~DPS Manager~: The primary configuration server, where analytics are defined, and the backend for the user interface.
- ~DPS Database Manager~: An interface to data that has been ingested by the system (uses TimescaleDB).
- ~DPS Batch Processor~: A worker process which runs computations (any number can be running at once).
- ~DPS Relay~: An adapter service which provides an API to send data to the system (allows for scheduling when data ingestion occurs).

** Installation
There are two different ways to install the system. First, there are instructions for installing a development environment. This should be done for anyone wanting to modify the code. The second installation, is a production installation which should be used when deploying the system to servers for high performance.

Both development and production installations require the use of Docker. If you do not have Docker installed already you can find it here: https://www.docker.com/ .

*** Development Installation
The first step is to provide an initial API key that will be hard coded into the DPS Manager for built-in services to use (such as DPS Batch Processor). In the root of this repository (the main ~dps~ directory), run this command (replacing "mysecret" with some secret text):

#+BEGIN_SRC sh
echo API_KEY=mysecret > docker/secrets.env
#+END_SRC

*Note that this text cannot contain spaces.*

Then to build all images and start containers run:
#+BEGIN_SRC sh
docker-compose up
#+END_SRC

This takes a while to complete.

After all containers are online, you can navigate to ~http://localhost:3005~ to view the UI.

*** Production Installation
The first step is to provide an initial API key that will be hard coded into the DPS Manager for built-in services to use (such as DPS Batch Processor). In the root of this repository (the main ~dps~ directory), run this command (replacing "mysecret" with some secret text):

#+BEGIN_SRC sh
echo API_KEY=mysecret > docker/secrets.env
#+END_SRC

*Note that this text cannot contain spaces.*

Next, create a ~.env~ file in: ~dps_ui/.env~ that contains the URL that is publicly available for DPS. Assign the name ~REACT_APP_DPS_HOST~ to our value using an equals sign. For example, when deploying to a server called "tianpar.cs.uwm.edu", I created a file with the following contents:

#+BEGIN_SRC sh
REACT_APP_DPS_HOST=tianpar.cs.uwm.edu
#+END_SRC

Next, create a ~prod.override.env~ file in: ~docker/dps_manager/prod.override.env~ that contains the URL that is publicly available for DPS. Assign the name ~DPS_HOST~ to our value using an equals sign. For example, when deploying to a server called "tianpar.cs.uwm.edu", I created a file with the following contents:

#+BEGIN_SRC sh
DPS_HOST=tianpar.cs.uwm.edu
#+END_SRC

To build all images and start containers run:

#+BEGIN_SRC sh
docker-compose -f docker-compose.yml -f docker-compose.production.yml up
#+END_SRC


** Development FAQ

*** What are the default credentials?

When setting up a new environment with Docker, the DPS UI will ask you for credentials. To make the setup process easier, we created default credentials. It is expected that the administrator should change their password once logged in.
To perform the initial login use the username: ~admin~ and the password: ~password~.

*** How do I get Docker to update when I change DPS UI's package.json (the dependencies)?
Docker with Node projects is a mess at the moment. The node_modules directory causes caching issues. To get around this I've mounted dps_ui/src and dps_ui/public as volumes to the Docker container, but not the top-level directory dps_ui.
As a consequence, whenever you change the dependencies of DPS UI (in package.json) you have to rebuild the entire container. Here is how you can do this:

#+BEGIN_SRC sh
docker-compose build dps-ui && docker-compose up dps-ui
#+END_SRC

This will re-build the container, and start it.

*** How do you update the default systems?
There are default systems that are present when a new DPS Manager system is deployed. These are created via Django's "fixtures".
To update the fixtures, in DPS UI, modify your systems to have exactly the systems you would like to be present in the system on a fresh install.
Then, run the following command:

#+BEGIN_SRC sh
cd dps_manager && python3 manage.py dumpdata dps_manager_api.object --indent=2 > ./dps_manager_api/fixtures/objects.json
#+END_SRC

Now when you start a new DPS installation, it will have exactly the same objects that are in your current database. Be careful not to include things like ~AuthToken~ or ~BatchProcess~ along with this. You can manage which objects are in your database by navigating to the DPS Manager URL: ~http://dps-manager:8000/admin~, logging in with your admin credentials, and deleting any objects you don't want in the fixtures.

To manually load the fixtures (for testing), you can use this command (while in the ~dps_manager~ directory).

#+BEGIN_SRC 
python3 manage.py loaddata dps_manager_api/fixtures/objects.json
#+END_SRC

These fixtures are automatically loaded when using Docker only done once when the container is built.

*** How do I run migrations and load fixtures?

#+BEGIN_SRC sh
docker-compose exec dps_manager python manage.py migrate --noinput
docker-compose exec dps_manager python manage.py loaddata objects.json
#+END_SRC

*** Containers are not able to resolve DNS when deploy via Docker on Linux
I had this issue. I followed these steps (assuming Ubuntu):

#+BEGIN_SRC sh
apt-get install bridge-utils
pkill docker
iptables -t nat -F
ifconfig docker0 down
brctl delbr docker0
service docker restart
#+END_SRC

It seemed to be a configuration issue with Docker rather than how DPS's docker scripts are defined.
*** Containers are not updating after docker-compose down and up on Linux
You have to give Docker a flag to build. Here's an example (for production):

#+BEGIN_SRC sh
docker-compose down
docker-compose -f docker-compose.yml -f docker-compose.production.yml up --build
#+END_SRC
